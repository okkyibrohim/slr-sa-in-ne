{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8cc785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import metadata_parser as mp\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import undetected_chromedriver as uc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb83ffc",
   "metadata": {},
   "source": [
    "# Login Bibliopass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e58571f",
   "metadata": {},
   "source": [
    "Bibliopass is a remote publisher library owned by the University of Turin. Each remote publisher library may have a different login interface/scheme so you need to modify this login code. If you want to use a ScienceDirect subscription account, you also need to modify this login code. If you do not have access to log in to ScienceDirect, you cannot use this code (when we are not logged in, we may able to use this code but ScienceDirect usually only gives us a few pages of the search result so that the search result is not complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c4e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_sciencedirect():\n",
    "    sciencedirect_url = \"https://www-sciencedirect-com.bibliopass.unito.it/\"\n",
    "    driver = uc.Chrome()\n",
    "    driver.get(sciencedirect_url)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        username = driver.find_element_by_id(\"username\")\n",
    "        password = driver.find_element_by_id(\"password\")\n",
    "        username.send_keys(\"your_username\")\n",
    "        password.send_keys(\"your_password\")\n",
    "        driver.find_element_by_name(\"_eventId_proceed\").click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(5)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b19fb",
   "metadata": {},
   "source": [
    "# Get All Paper Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d6f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciencedirect = pd.read_excel(\"./paper-links/PaperLinks_ScienceDirect.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bea853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paper metadata\n",
    "list_source, list_querystring, list_querylinks, list_paperlinks = [], [], [], []\n",
    "list_year, list_title, list_conf_jour, list_authors, list_keywords, list_abstract = [], [], [], [], [], []\n",
    "driver = uc.Chrome() # driver = login_sciencedirect() # change not using bibliopass because it blocked ._.\n",
    "for index in range(0,len(sciencedirect[\"Paper Links\"])-1):\n",
    "    try:\n",
    "        # Get Page, change not using bibliopass because it blocked ._.\n",
    "        paper_url = re.sub(\"www-sciencedirect-com.bibliopass.unito.it\",\"www.sciencedirect.com\",sciencedirect[\"Paper Links\"][index])\n",
    "        driver.get(paper_url)\n",
    "        time.sleep(5)\n",
    "        # Get Year\n",
    "        try:\n",
    "            year_html = driver.find_element_by_xpath(\"//meta[@name='citation_publication_date']\")\n",
    "            year = year_html.get_attribute(\"content\").split(\"/\")[0].strip()\n",
    "        except:\n",
    "            year = \"failed_to_scrap\"\n",
    "        # Get Title\n",
    "        try:\n",
    "            title_html = driver.find_element_by_xpath(\"//meta[@name='citation_title']\")\n",
    "            title = title_html.get_attribute(\"content\").strip()\n",
    "        except:\n",
    "            title = \"failed_to_scrap\"\n",
    "        # Get Conf/Journal Name\n",
    "        try:\n",
    "            conf_jour_html = driver.find_element_by_xpath(\"//meta[@name='citation_journal_title']\")\n",
    "            conf_jour_name = conf_jour_html.get_attribute(\"content\").strip()\n",
    "        except:\n",
    "            conf_jour_name = \"failed_to_scrap\"\n",
    "        # Get Authors\n",
    "        try:\n",
    "            get_authors = driver.find_elements_by_css_selector(\"a[class='author size-m workspace-trigger']\")\n",
    "            for i in range(0,len(get_authors)):\n",
    "                if i == 0:\n",
    "                    authors = get_authors[i].text.split(\"\\n\")[0]\n",
    "                else:\n",
    "                    authors = authors+\", \"+get_authors[i].text.split(\"\\n\")[0]\n",
    "        except:\n",
    "            authors = \"failed_to_scrap\" \n",
    "        # Get Keywords\n",
    "        try:\n",
    "            get_keywords = driver.find_elements_by_css_selector(\"div[class='keyword']\")\n",
    "            for i in range(0,len(get_keywords)):\n",
    "                if i == 0:\n",
    "                    keywords = get_keywords[i].text.split(\"\\n\")[0]\n",
    "                else:\n",
    "                    keywords = keywords+\", \"+get_keywords[i].text.split(\"\\n\")[0]\n",
    "        except:\n",
    "            keywords = \"failed_to_scrap\"\n",
    "        # Get Abstract\n",
    "        try:\n",
    "            abstract_html = driver.find_elements_by_css_selector(\"div[class='abstract author']\")\n",
    "            abstract = abstract_html[0].text\n",
    "            abstract = re.sub(\"Abstract\\n\",\"\",abstract)\n",
    "            abstract = re.sub(\"\\n\",\"\",abstract).strip()\n",
    "        except:\n",
    "            abstract = \"failed_to_scrap\"\n",
    "\n",
    "        \n",
    "        attribute = [year, title, conf_jour_name, authors, keywords, abstract]\n",
    "        if all(a == \"failed_to_scrap\" for a in attribute): # We stop if we cathed as bot\n",
    "            break\n",
    "        else: # Append to the list\n",
    "            list_source.append(\"ScienceDirect\")\n",
    "            list_querystring.append(sciencedirect[\"Query\"][index])\n",
    "            list_querylinks.append(sciencedirect[\"Query Links\"][index])\n",
    "            list_paperlinks.append(sciencedirect[\"Paper Links\"][index])\n",
    "            list_year.append(year)\n",
    "            list_title.append(title)\n",
    "            list_conf_jour.append(conf_jour_name)\n",
    "            list_authors.append(authors)\n",
    "            list_keywords.append(keywords)\n",
    "            list_abstract.append(abstract)\n",
    "    except:\n",
    "        break\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b067b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap to dataframe and safe to excel\n",
    "sd_metadata = pd.DataFrame({'Source': list_source,\n",
    "                                  'Query': list_querystring,\n",
    "                                  'Query Links': list_querylinks,\n",
    "                                  'Paper Links': list_paperlinks,\n",
    "                                  'Year':list_year,\n",
    "                                  'Title':list_title,\n",
    "                                  'Conf/Journal Name':list_conf_jour,\n",
    "                                  'Authors':list_authors,\n",
    "                                  'Keywords':list_keywords,\n",
    "                                  'Abstract':list_abstract})\n",
    "sd_metadata.to_excel(\"./paper-metadata/PaperMetadata_ScienceDirect.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
